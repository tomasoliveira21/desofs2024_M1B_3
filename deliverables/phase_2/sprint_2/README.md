# Phase 2 - Sprint 2

## Objective

In this sprint we were expected to develop the rest of the application, following the best practices possible and implementing/enhancing the pipeline and/or tests.

## Supabase

Supabase provided us with the Database, Authentication and Storage systems needed to make our backend application. Our database is hosted on AWS, in Europe and is fully accessible as any other database would be, but higly discouraged since Supabase provides all the means to safely manage the database without risk of data corruption.

![Supabase Architecture](img/supabase-architecture.svg)

Supabase uses Kong as the webserver for the multiple paths and, specifically for the database, it implements a REST ([PostgREST](https://postgrest.org/en/v12/)) interface on top of Postgres that allows multiple operations such as Authentication and Authorization.

### Database

Under the hood, it uses [Row Level Security](https://supabase.com/docs/guides/database/postgres/row-level-security) rules, following the official [Row Security Policies](https://www.postgresql.org/docs/current/ddl-rowsecurity.html) Postgres Implementation and, for us, this means that we can implement our RBAC in the Backend and at the Database level. When a RLS rule is created, prior to an UPDATE, INSERT, DELETE or any operation these policies are validated against the user that is trying to perform the action; if the rule fails than the action is not carried on (for instance `default` users cannot delete tweets so they cannot perform a `DELETE FROM socialnet."Tweets"` operation).

Supabase also allows custom [Custom Claims & Role-based Access Control (RBAC)](https://supabase.com/docs/guides/database/postgres/custom-claims-and-role-based-access-control-rbac?queryGroups=language&language=plpgsql) by implementing a set of rules and Postgres policies and these are reflected in the generated [JWT token](https://supabase.com/docs/guides/auth/jwts), so we can control operations in the backend by validating this token.

We ended up creating the following tables on the `socialnet` schema in our database:

![Database Schema](img/database_schema.png)

In this database schema there are references to the table `auth.user.id`, which is a managed table by Supabase and has information regarding the users that are registered onto the project, such as if they have OTP enabled, MFA, if they are verified, their Unique ID, etc. We reference that table for our operations but cannot change the table itself.

#### Users

To fetch user information we ended up creating a [View](https://www.postgresql.org/docs/current/sql-createview.html), which queries information from multiple tables and allows users to query this view as if it was a table. From a security point-of-view this is better than managing a new table because these queries are ran by Postgres and do not accept user inputs, so information cannot be changed while querying a view.

```sql
CREATE OR REPLACE VIEW
  socialnet."users" AS
SELECT
  u.id,
  u.email,
  ur.role,
  LOWER(
    regexp_replace(
      TRIM(SPLIT_PART(u.email, '@', 1)),
      '[^a-zA-Z0-9]',
      '_',
      'g'
    )
  ) AS username
FROM
  auth.users AS u
  INNER JOIN socialnet.user_roles AS ur ON u.id = ur.user_id;
```

![Users View](img/users_view.png)

This view feeds our backend with information regarding the users that we can then return to the frontend and references the original `auth.users` table without changing any information.

#### Trends

For the Trends functionality we have created another view that is dynamic, showing us the top-10 Hashtags from the last 24 hours.

```sql
DROP VIEW IF EXISTS socialnet.trends;
CREATE VIEW socialnet.trends AS
SELECT
    name,
    COUNT(*) AS count,
    ROW_NUMBER() OVER (ORDER BY COUNT(*) DESC) AS position
FROM     socialnet."Hashtags"
WHERE    created_at >= Now() - interval '1 DAYS'
group BY name
ORDER BY count DESC limit 10;
```

![Trends View](img/trends_view.png)

#### Tweets and Hashtags

##### Tweets

```sql
create table
  socialnet."Tweets" (
    id bigint generated by default,
    created_at timestamp with time zone not null default now(),
    content text not null,
    uuid uuid not null default gen_random_uuid () as identity,
    user_uuid uuid not null default auth.uid (),
    constraint Tweets_pkey primary key (id),
    constraint Tweets_uuid_key unique (uuid),
    constraint Tweets_user_uuid_fkey foreign key (user_uuid) references auth.users (id) on update cascade on delete cascade
  ) tablespace pg_default;
```

Our Tweets are **not** identified by an incremental `id` but by an [UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier) that is generated whenever a Tweet is posted and provides an extra security against SQL injection attacks, since it would be near impossible to randomly guess an UUID since these values depend on the Operating System that is generating them, the time, the content, etc.

To these table we applied the following RLS policies:

```sql
create policy "Allow tweet post" on socialnet."Tweets" for insert to authenticated
with
  check (
    (
      select
        auth.uid ()
    ) = user_id
  );
create policy "Allow authorized delete" on socialnet."Tweets" for delete using (
  (
    SELECT
      socialnet.authorize ('tweet.delete')
  )
);
```

Any authenticated (default PostgREST role for authenticated users and, in our case, corresponds to the `default` user)  user can post a Tweet since it is a basic functionallity of the Socialnet Application, but only users that have the `tweet.delete` permission can perform a DELETE operation (more information on [RBAC](#rbac)).

##### Hashtags

The hashtags are identified by an incremental ID because they are associated with a tweet and there is the Foreign Key constraint that prevents a single delete of an Hashtag while the referenced Tweet still exists and they simply contain a name.

```sql
create table
  socialnet."Hashtags" (
    id bigint generated by default as identity,
    created_at timestamp with time zone not null default now(),
    name text not null,
    tweet_uuid uuid not null,
    constraint Hashtags_pkey primary key (id),
    constraint Hashtags_tweet_uuid_key unique (tweet_uuid),
    constraint Hashtags_tweet_uuid_fkey foreign key (tweet_uuid) references socialnet."Tweets" (uuid) on update cascade on delete cascade
  ) tablespace pg_default;
```

We created the following RLS policies:

```sql
create policy "Allow authorized delete" on socialnet."Hashtags" for delete using (
  (
    SELECT
      socialnet.authorize ('hashtag.delete')
  )
);
```

Following the Tweets logic, only users with the `hashtag.delete` permission can perform a `DELETE` operation on this table.

#### RBAC

For the RBAC at the Database/Authentication level we created a series of configurations that allows us to *inject* a new field on the JWT token associated with each user session and that we can then use in the Backend or Frontend. With these configurations we also created RLS policies that define what users can and cannot do on the database given their roles.

```sql
-- Provide authorization for the PostgREST API user that handles the authentication of users
grant usage on schema socialnet to supabase_auth_admin;

-- Block Authenticated and Anonymous users to perform operations on the socialnet."user_roles" table
revoke all on table socialnet."user_roles"
from
  authenticated,
  anon;

-- Allow PostgREST authentication user to query the socialnet."user_roles" table to handle user authentication
create policy "Allow auth admin to read user roles" ON socialnet."user_roles" as permissive for
SELECT to supabase_auth_admin using (true);

-- Create the ENUM type with the possible Permissions for the application
create type socialnet."app_permission" as enum('tweet.delete', 'trends.view', 'hashtag.delete');

-- Create the Application Roles
create type socialnet.app_role as enum('default', 'premium', 'admin');

-- Create the socialnet."user_roles" table that associates <user_uuid>-<app_role>
create table
  socialnet."user_roles" (
    id bigint generated by default as identity primary key,
    user_id uuid references auth.users on delete cascade not null,
    role socialnet.app_role not null,
    unique (user_id, role)
);

comment on table socialnet."user_roles" is 'Application Role';

-- Creates the socialnet."role_permissions" that associates <role>-<app_permission>
create table
  socialnet."role_permissions" (
    id bigint generated by default as identity primary key,
    role socialnet.app_role not null,
    permission socialnet.app_permission not null,
    unique (role, permission)
);

comment on table socialnet.role_permissions is 'Application Permission';

-- Create the auth hook function that modifies the JWT token with the custom role field
create
or replace function socialnet."custom_access_token_hook" (event jsonb) returns jsonb language plpgsql stable as $$
  declare
    claims jsonb;
    user_role socialnet.app_role;
  begin
    -- Check if the user is marked as admin in the profiles table
    select role into user_role from socialnet."user_roles" where user_id = (event->>'user_id')::uuid;

    claims := event->'claims';

    if user_role is not null then
      -- Set the claim
      claims := jsonb_set(claims, '{user_role}', to_jsonb(user_role));
    else
      claims := jsonb_set(claims, '{user_role}', 'default');
    end if;

    -- Update the 'claims' object in the original event
    event := jsonb_set(event, '{claims}', claims);

    -- Return the modified or original event
    return event;
  end;
$$;

-- Create the function that authorizes actions based on the association of <role>-<app_permission>
create
or replace function socialnet."authorize" (requested_permission socialnet.app_permission) returns boolean as $$
declare
  bind_permissions int;
  user_role socialnet.app_role;
begin
  select (auth.jwt() ->> 'user_role')::socialnet.app_role into user_role;

  select count(*)
  into bind_permissions
  from socialnet."role_permissions"
  where role_permissions.permission = requested_permission
    and role_permissions.role = user_role;

  return bind_permissions > 0;
end;
$$ language plpgsql stable security definer
set
  search_path = '';

-- Views do not have RLS but the queries underneath must respect RLS so we enable security_invoker for that effect
-- Enable security_invoker for the Trends view
ALTER VIEW socialnet."trends"
SET
  (security_invoker = on);

-- Enable security_invoker for the Users view
ALTER VIEW socialnet."users"
SET
  (security_invoker = on);
```

Whenever a new user is created it receives the role `default` so we also enabled this behaviour using a function that runs after a new user is created:

```sql
-- Create a public function that can be run whenever we need
create or replace function public.handle_new_user () returns trigger as $$ begin
    insert into socialnet."users" (id, aud, email)
    values (new.id, new.aud, new.email);
    insert into socialnet.user_roles (user_id, role)
    values (new.id, 'default');
    return new;
end;
$$ language plpgsql security definer;

-- Create a trigger that runs the function public.handle_new_user() after a new user is inserted on the auth.users table
create trigger on_auth_user_created
after insert on auth.users for each row execute procedure public.handle_new_user();
```

In order to allow administrators to change the roles of other users we enabled the following:

```sql
-- Authenticated users can view their own role
CREATE POLICY "Users can view their own role" ON socialnet."user_roles" FOR
SELECT TO authenticated USING (true);

-- This function will return a boolean by querying the socialnet.user_roles table and verifying if the authenticated user is an admin
CREATE OR REPLACE FUNCTION socialnet.is_current_user_admin() RETURNS boolean AS $$
BEGIN
    RETURN EXISTS (
        SELECT 1
        FROM socialnet.user_roles ur
        WHERE ur.user_id = (select auth.uid())
        AND ur.role = 'admin'
    );
END;
$$ LANGUAGE plpgsql;

-- If the user is an Admin they can alter the roles of other users (UPDATE the table socialnet."user_roles")
CREATE POLICY update_role_policy ON socialnet."user_roles"
FOR UPDATE
USING (socialnet.is_current_user_admin())
```

With this we concluded the configuration of the Database, as well as RBAC policies and security configurations we want to enable. All has been done manually, so Supabase only provided a user-friendly UI to manage the database, but we also have instructions to perform the same Database connection using [PGAdmin](../../../backend/README.md#pgadmin) (would also work with standard tools like `psql`).

### Storage

Supabase provides us with an [S3-compatible object storage service](https://supabase.com/docs/guides/getting-started/architecture#storage-api-large-file-storage) that we use to host our profile pictures and tweet images. Database policies also apply here since each object has it's own corresponding row in the `auth.storage` table and, by using a REST API with authorization, Supabase is capable of validating if whoever is requesting an object is allowed to perform that request, which introduces another extra level of security for data-at-rest (by also using RLS policies).

We created the following RLS policies for the storage table:

```sql
CREATE POLICY "Users can Upload Profile Pictures 1mkux3k_0" ON storage.objects FOR
SELECT TO authenticated USING (bucket_id = 'socialnet');
CREATE POLICY "Users can Upload Profile Pictures 1mkux3k_1" ON storage.objects FOR
INSERT TO authenticated WITH CHECK (bucket_id = 'socialnet');
```

## Backend

We have fully developed our backend using Python 3.11.

We used Pydantic for data and model validation, FastAPI to serve our endpoints and the Supabase Python Client to access our Supabase Project.

### Domain

We created the [domain classes](../../../backend/src/backend/domain/) for:

- Hashtags
- Tweets
- Users

We have implemented Data Transfer Objects that can be used to return information from the database. The base models implemented serve as the input for the FastAPI application and perform validation of the input data, using the [Annotated Types such as constrained strings](https://docs.pydantic.dev/latest/concepts/types/).

```python
class Tweet(BaseModel):
    content: Annotated[
        str,
        StringConstraints(
            min_length=settings.tweet_min_size,
            max_length=settings.tweet_max_size,
        ),
    ]

    @computed_field
    @property
    def hashtags(self) -> List[Hashtag]:
        return TypeAdapter(List[Hashtag]).validate_python(
            [{"name": h} for h in re.findall(r"#(\w+)", self.content)]
        )


class TweetDto(Tweet):
    id: int
    created_at: datetime
    uuid: UUID
    user_uuid: UUID
```

Pydantic allows to create `compute_field` properties on the classes which allow to fetch information after the object is created, without the need to modify it.

### Configurations

We implemented a [settings class](../../../backend/src/backend/infrastructure/config.py) that validates the data from a Dotenv file and parses it, returning a class with the attributes filled by the variables present in that dotenv file.

```python
class Settings(BaseSettings):
    model_config = SettingsConfigDict(
        env_file=".env", env_file_encoding="utf-8", extra="allow"
    )
    tweet_min_size: int
    tweet_max_size: int
    supabase_url: str
    supabase_key: str
    jwt_secret_key: str
    jwt_algorithms: List[str]
    jwt_audience: List[str]
    redis_host: str
    redis_port: int
    redis_password: str
    cors_origins: List[str]
```

Comparing to the [first sprint](../sprint_1/) we have improved our secret management by not commiting to the GitHub repository the dotenv file and by using this class, so no more `os.environ.get()` calls are made, which reduces risk of forgetness of variables hard-coded. This class is used in all the code to fetch settings global to all the Backend.

### MVC

#### API

The [`main.py`](../../../backend/src/backend/main.py) file includes the declaration of the FastAPI `app`:

```python
app = FastAPI(
    title="SocialNet - Backend",
    description="The Backend for the SocialNet application",
    dependencies=[Depends(JWTBearer()), Depends(RateLimiter(times=20, seconds=5))],
    lifespan=lifespan,
)
```

After that, we have added a CORS middleware to improve security and we are feeding the CORS domain from the [dotenv](#configurations) file:

```python
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

We then proceed to create the Routers that will aggregate the paths for our API operations:

```python
tweet_router = APIRouter(prefix="/tweet", tags=["Tweets"])
hashtag_router = APIRouter(prefix="/hashtag", tags=["Hashtag"])
user_router = APIRouter(prefix="/user", tags=["User"])
```

Finally we add methods to the routers and add the routers to the app previously created:

```python
@tweet_router.get(
    "/user/self", dependencies=[Depends(RBAC(minimum_role=UserRole.default))]
)
def get_self_tweets(request: Request) -> List[TweetDto]:
    return tweet_service.get_self_tweet(request=request)

...

# ROUTERS
app.include_router(tweet_router)
app.include_router(hashtag_router)
app.include_router(user_router)
```

#### Services

We instantiate the Services needed in the [`main.py` file](../../../backend/src/backend/main.py#L58-L61) and the routes call the services to perform the operations.

Each service contains the logger used for the application and the repository associated with the DDD Aggregate it corresponds to:

```python
class HashtagService:
    def __init__(self):
        self.__repository = HashtagRepository()
        self.__logger = Logger().get_logger()
```

Then each method in the service logs the operation and the user performing the operation and calls the repository. In case the repository methods fail the exception handling is performed at this layer:

```python
def get_hashtags(self, request: Request) -> List[HashtagDto]:
    self.__logger.info(f"[{request.state.credentials['sub']}] get all hashtags")
    try:
        with single_read_object(
            self.__repository.get_hashtags(request=request)
        ) as hashtags:
            return hashtags
    except InvalidSupabaseResponse as e:
        raise HTTPException(status_code=500, detail=str(e))
```

In this layer, the object is destroyed after beind returned, using a combination of `with` and the [Single Read Object method](#single-read-objects).

#### Repositories

Each repository is called by a service and it is a Singleton, and includes the Supabase Client to perform actions agains the database, as well as an [TypeAdapter](https://docs.pydantic.dev/latest/concepts/type_adapter/) to transform the information from the database to the user:

```python
class TweetRepository:
    __instance = None

    def __new__(cls):
        if cls.__instance is None:
            cls.__instance = super(TweetRepository, cls).__new__(cls)
            cls.__instance.__initialize_params()
        return cls.__instance

    def __initialize_params(self):
        self.__client = SupabaseSingleton().get_client()
        self.__adapter = TypeAdapter(List[TweetDto])
        self.__logger = Logger().get_logger()
```

Each method sets the session associated with the user that is performing the request so that the RLS policyes correctly apply and then the exceptions are validated, as well as transforming the fetched data onto DTOs so that they can be presented to the user:

```python
def get_all_tweets(self, request: Request) -> List[TweetDto]:
    try:
        self.__client.auth.set_session(
            access_token=request.state.jwt, refresh_token=""
        )
        response = self.__client.table("Tweets").select("*").execute()
        self.__client.auth.sign_out()
        return self.__adapter.validate_python(response.data)
    except Exception as e:
        self.__logger.error(f"[{request.state.credentials['sub']}] {e}")
        raise InvalidSupabaseResponse("Could not get tweets at this moment.")
```

### Authentication & RBAC

We have two separate classes:

[Auth](../../../backend/src/backend/application/auth.py): performs the validations regarding the JWT token passed as the Authentication Bearer token for each route:

```python
class JWTBearer(HTTPBearer):
    def __init__(self, auto_error: bool = True):
        super(JWTBearer, self).__init__(auto_error=auto_error)

    async def __call__(self, request: Request):
        credentials: HTTPAuthorizationCredentials | None = await super(
            JWTBearer, self
        ).__call__(request)
        if credentials:
            if not credentials.scheme == "Bearer":
                raise HTTPException(
                    status_code=403, detail="Invalid authentication scheme."
                )
            else:
                request.state.jwt = credentials.credentials

            try:
                decoded_token = jwt.decode(
                    jwt=request.state.jwt,
                    key=settings.jwt_secret_key,
                    algorithms=settings.jwt_algorithms,
                    audience=settings.jwt_audience,
                )
                request.state.credentials = decoded_token
            except Exception:
                raise HTTPException(
                    status_code=500, detail="Could not decode JWT Token."
                )

            if not request.state.credentials["exp"] >= time():
                raise HTTPException(status_code=403, detail="JWT Token has expired.")

            try:
                request.state.user = UserService().get_self_user(request=request)
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))

            return credentials.credentials
```

The authentication performs the following actions:

1. Verify if the JWT bearer token is present
2. Decode the JWT token using the JWT configurations provided by supabase
3. Verify if the JWT token is not expired
4. Verify if both the user and sessions exist in Supabase

We then use the `request.state` to transfer this informatio between the layers.

[RBAC](../../../backend/src/backend/application/rbac.py): performs the validation of RBAC, using a system of hierarchy regarding the roles and is injected in each route:

```python
class RBAC:
    def __init__(self, minimum_role: UserRole, auto_error: bool = True):
        super(RBAC, self).__init__()
        self._minimum_role: UserRole = minimum_role

    def __call__(self, request: Request):
        try:
            user_role = request.state.user.role
        except ValueError:
            raise HTTPException(status_code=403, detail="Invalid role")
        if user_role.value.hierarchy < self._minimum_role.value.hierarchy:
            raise HTTPException(
                status_code=403, detail="User does not have enough permissions."
            )
```

The user roles are created using an hierarchy system, where `default < premium < admin`:

```python
class Role(BaseModel):
    name: Annotated[
        str,
        StringConstraints(
            min_length=1, max_length=24, to_lower=True, strip_whitespace=True
        ),
    ]
    hierarchy: Annotated[int, Field(ge=0)]


class DefaultRole(Role):
    def __init__(self, name="default", hierarchy=0):
        super().__init__(name=name, hierarchy=hierarchy)


class PremiumRole(Role):
    def __init__(self, name="premium", hierarchy=1):
        super().__init__(name=name, hierarchy=hierarchy)


class AdminRole(Role):
    def __init__(self, name="admin", hierarchy=2):
        super().__init__(name=name, hierarchy=hierarchy)
```

This RBAC class is then added as a dependency on each method with the minimum needed role to perform that action: `@tweet_router.get("/all", dependencies=[Depends(RBAC(minimum_role=UserRole.default))])`. This will act as an RBAC validation on top of the RLS policies implemented. 

### Logging and Error Handling

### Security

#### Single-Read Objects

To stand-out this feature, we have implemented an [`utils.py` class](../../../backend/src/backend/application/utils.py) that has the following code:

```python
@contextmanager
def single_read_object(object: Any):
    try:
        yield object
    finally:
        del object
```

The `yield` instruction acts as the return value of the `single_read_object` function and when that return is used by the caller of this function (`finally`) then the object is destroyed, even if there are references poiting to the object.

This is used in the service layer to destroy the object after the repository returns the values requested:

```python
with single_read_object(
                self.__repository.get_hashtags(request=request)
            ) as hashtags:
                return hashtags
```

#### Private Attributes

The classes created include private attributes that are prefixed by `__` and cannot be accessed outside the class itself. This increases security when transitioning data from one layer to the other.

```python
class HashtagService:
    def __init__(self):
        self.__client = SupabaseSingleton().get_client()
        self.__repository = HashtagRepository()
        self.__logger = Logger().get_logger()
```

#### Others

We created a singleton for our Supabase Client and we are returning a copy of the instance and not direct references to the client instance, as we can see [here](../../../backend/src/backend/infrastructure/supabase_auth.py#L23-L26):

```python
@staticmethod
def get_client() -> Client:
    instance = SupabaseSingleton()
    return instance.__client
```